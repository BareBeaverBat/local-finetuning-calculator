{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:15.649316Z",
     "start_time": "2024-04-11T02:46:14.080264Z"
    }
   },
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset, Dataset"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:22.884720Z",
     "start_time": "2024-04-11T02:46:15.649316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from trl.trainer import ConstantLengthDataset"
   ],
   "id": "50c8dfb9ed9d1242",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:22.900356Z",
     "start_time": "2024-04-11T02:46:22.884720Z"
    }
   },
   "cell_type": "code",
   "source": "# notebook_login()",
   "id": "d8958b7b6bb1a452",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:24.236878Z",
     "start_time": "2024-04-11T02:46:22.900356Z"
    }
   },
   "cell_type": "code",
   "source": "eli5: Dataset = load_dataset(\"eli5_category\", split=\"train[:5000]\", trust_remote_code=True)",
   "id": "996b8e751778e120",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:24.268141Z",
     "start_time": "2024-04-11T02:46:24.236878Z"
    }
   },
   "cell_type": "code",
   "source": "eli5_train_test = eli5.train_test_split(test_size=0.2)",
   "id": "12adddb58b5f39e2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:24.284195Z",
     "start_time": "2024-04-11T02:46:24.268141Z"
    }
   },
   "cell_type": "code",
   "source": "# eli5_train_test[\"train\"][0]",
   "id": "382af01843cb8b2d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:24.299863Z",
     "start_time": "2024-04-11T02:46:24.284195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_id = \"google/gemma-2b\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,#todo explore whether it actually increases overall memory usage to change this to float32\n",
    "    bnb_4bit_use_double_quant=True# reminder that this makes computing the total memory used by the frozen weights even more complicated, something about reducing the size of the quantization constants that are used for remembering how to dequantize a given block of quantized weights? by the equivalent of 0.4 bits per parameter, per docs\n",
    "    \n",
    ")"
   ],
   "id": "b6be1ca8c73ff384",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:41.623842Z",
     "start_time": "2024-04-11T02:46:24.299863Z"
    }
   },
   "cell_type": "code",
   "source": "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
   "id": "a9e5c90629ed8151",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "366baf70b9a14cebafcf1aecef60ec35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:42.601182Z",
     "start_time": "2024-04-11T02:46:41.623842Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained(model_id)",
   "id": "3eb0992414f9a31f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:42.617212Z",
     "start_time": "2024-04-11T02:46:42.601182Z"
    }
   },
   "cell_type": "code",
   "source": "# tokenizer.padding_side = \"right\" #todo based on runtime warning while building SFTTrainer, can try this if problems occur, but by default I think I should respect the default for the Gemma Tokenizer",
   "id": "31d4b9c83121bfa",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:42.632862Z",
     "start_time": "2024-04-11T02:46:42.617212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", # just lora'ing attention heads for now, to mimic original LoRA paper\n",
    "                    #\"gate_proj\", \"up_proj\", \"down_proj\" todo what is gate_proj? I think up_proj is first weights matrix of MLP block (fan out) and down_proj is second weights matrix of MLP block (fan in), but no idea what gate_proj is\n",
    "                    ],# reminder, can use \"all-linear\" (not inside list) for the expansive case https://huggingface.co/docs/peft/developer_guides/lora#qlora-style-training\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    use_rslora=True\n",
    "    #todo investigate whether it's worth trying Dora, iirc that was said to be especially helpful when lora rank is low\n",
    ")"
   ],
   "id": "6cf6bd082de65da1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:42.648482Z",
     "start_time": "2024-04-11T02:46:42.632862Z"
    }
   },
   "cell_type": "code",
   "source": "seq_len = 128",
   "id": "fc13a783360c7582",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:42.664132Z",
     "start_time": "2024-04-11T02:46:42.648482Z"
    }
   },
   "cell_type": "code",
   "source": "# tokenizer",
   "id": "24d60bf2a96170d9",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:42.711369Z",
     "start_time": "2024-04-11T02:46:42.664132Z"
    }
   },
   "cell_type": "code",
   "source": "eli5_train_test = eli5_train_test.flatten()",
   "id": "9c43405600c0b7aa",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:42.727003Z",
     "start_time": "2024-04-11T02:46:42.711369Z"
    }
   },
   "cell_type": "code",
   "source": "# eli5_train_test[\"train\"][0]",
   "id": "daa6fb5711441362",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:42.742630Z",
     "start_time": "2024-04-11T02:46:42.727003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fix_data(record):\n",
    "    '''\n",
    "    make dataset usable by TRL (i.e. its classes have a dataset_text_field param, and that column must be string-type, \n",
    "    not list<string> type)\n",
    "    :param record: record where the text column is actually a length-1 list column\n",
    "    :return: record where the text column is straightforwardly a text-type column\n",
    "    '''\n",
    "    record[\"answers.text\"] = record[\"answers.text\"][0]\n",
    "    return record"
   ],
   "id": "c11c55165ed71a1e",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:43.697235Z",
     "start_time": "2024-04-11T02:46:42.742630Z"
    }
   },
   "cell_type": "code",
   "source": "eli5_train_test = eli5_train_test.map(fix_data)",
   "id": "6774fe8dc74c1975",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db622128d9fb46f0a104d1b11eac41df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "379d66dfac6d47e8bd538784aa985cdc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:43.712812Z",
     "start_time": "2024-04-11T02:46:43.702298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fixed_len_train_dset =  ConstantLengthDataset(tokenizer, eli5_train_test[\"train\"], \"answers.text\", seq_length=seq_len)\n",
    "fixed_len_eval_dset =  ConstantLengthDataset(tokenizer, eli5_train_test[\"test\"], \"answers.text\", seq_length=seq_len)"
   ],
   "id": "a573582827fb65bd",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:43.729448Z",
     "start_time": "2024-04-11T02:46:43.714359Z"
    }
   },
   "cell_type": "code",
   "source": "# fixed_len_train_dset.__iter__().__next__()",
   "id": "8cba9279ee911528",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:45.066965Z",
     "start_time": "2024-04-11T02:46:43.731416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=fixed_len_train_dset,\n",
    "    eval_dataset=fixed_len_eval_dset,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        # gradient_accumulation_steps=4,#todo don't want to touch this until I understand it\n",
    "        warmup_steps=2,\n",
    "        max_steps=10,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_32bit\"#can try paged_adamw_8bit in absolute worst case\n",
    "    ),\n",
    "    packing=True,\n",
    "    # dataset_text_field=\"answers.text\",\n",
    "    peft_config=lora_config\n",
    ")"
   ],
   "id": "bb91189afd88e43a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssili\\PycharmProjects\\local-finetuning-calculator\\venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:245: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssili\\PycharmProjects\\local-finetuning-calculator\\venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:317: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssili\\PycharmProjects\\local-finetuning-calculator\\venv\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssili\\PycharmProjects\\local-finetuning-calculator\\venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:341: UserWarning: You passed `packing=True` to the SFTTrainer, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:45.082542Z",
     "start_time": "2024-04-11T02:46:45.066965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#todo set up pytorch gpu mem tracking\n",
    "# torch.cuda.memory._record_memory_history()\n",
    "\n",
    "\n",
    "#investigate whether WSL 2 could be used to get around the \"no windows support for gpu mem visualization\" issue\n",
    "\n"
   ],
   "id": "15b1858ee0c5a093",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:46:45.098170Z",
     "start_time": "2024-04-11T02:46:45.082542Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "id": "87c463b4f651c2c5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:47:12.304411Z",
     "start_time": "2024-04-11T02:46:45.098170Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "9bbb8eba92c1f2a5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssili\\PycharmProjects\\local-finetuning-calculator\\venv\\lib\\site-packages\\transformers\\models\\gemma\\modeling_gemma.py:573: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:21, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.518100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.929400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.158600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.372100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.577600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>7.722700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.537700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=5.534050869941711, metrics={'train_runtime': 27.0802, 'train_samples_per_second': 0.369, 'train_steps_per_second': 0.369, 'total_flos': 15227950202880.0, 'train_loss': 5.534050869941711, 'epoch': 0.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:47:12.320033Z",
     "start_time": "2024-04-11T02:47:12.304411Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "894bb28458e3d280",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:47:12.327215Z",
     "start_time": "2024-04-11T02:47:12.320033Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8cba29dfdce13b50",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:47:12.335700Z",
     "start_time": "2024-04-11T02:47:12.328591Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2e22d0047400941d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:47:12.343513Z",
     "start_time": "2024-04-11T02:47:12.336710Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bc3774ab88ab1128",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T02:47:12.364683Z",
     "start_time": "2024-04-11T02:47:12.345963Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f3cd155151026d7f",
   "outputs": [],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
